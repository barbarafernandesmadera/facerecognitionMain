{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from admin.database_registration import DBRegistration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instance class construtor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "registration = DBRegistration('data/db/', 'data/db_raw/', 'data/db_control.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add a new image to the database: It needs to be in the 'data/db_raw' folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject registered at subject id: 36684a5a-3bc5-11ef-90e7-28d0ea5d9ad4\n"
     ]
    }
   ],
   "source": [
    "registration.register(\"Katia.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup DB with real videos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exclusive for model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import glob\n",
    "from facerecognition.utils import (get_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_central_frame_videos(folder, frame_skip=10, N=100):\n",
    "    \"\"\"\n",
    "    Extracts the central frame from a list of video files in a specified folder.\n",
    "\n",
    "    Parameters:\n",
    "    folder (str): The path to the folder containing the video files.\n",
    "    frame_skip (int): The number of frames to skip between each frame extraction. Default is 10.\n",
    "    N (int): The maximum number of videos to process. Default is 100.\n",
    "\n",
    "    Returns:\n",
    "    dict: A dictionary where the keys are the video names (without extension) and the values are the central frames.\n",
    "    \"\"\"\n",
    "    video_frames = {}\n",
    "    for video_path in glob.glob(os.path.join(folder, '*.mp4'))[:N]:\n",
    "        video_name = os.path.basename(video_path).split('.')[0]\n",
    "        frames = get_frames(video_path, frame_skip=frame_skip)\n",
    "        central_position = len(frames) // 2\n",
    "        central_value = frames[central_position]\n",
    "        video_frames[video_name] = central_value\n",
    "    return video_frames\n",
    "\n",
    "def save_frame(image_name, frame):\n",
    "    \"\"\"\n",
    "    Saves a single frame as an image file.\n",
    "\n",
    "    Parameters:\n",
    "    image_name (str): The name to be given to the saved image file (without extension).\n",
    "    frame (numpy.ndarray): The image frame to be saved.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    cv2.imwrite(f\"data/db_raw/{image_name}.png\", frame)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_frame = get_central_frame_videos('data/videos/real', frame_skip=50, N=10)\n",
    "for image_name, frame in real_frame.items():\n",
    "    image_name = image_name.split('real_')[-1].split('_')[0]\n",
    "    save_frame(image_name, frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject registered at subject id: 702242e5-3bc5-11ef-81ea-28d0ea5d9ad4\n",
      "Subject registered at subject id: 704e690f-3bc5-11ef-95aa-28d0ea5d9ad4\n",
      "Subject registered at subject id: 70762057-3bc5-11ef-ac0d-28d0ea5d9ad4\n",
      "Subject registered at subject id: 70b2f2b6-3bc5-11ef-aca5-28d0ea5d9ad4\n",
      "Subject registered at subject id: 70f67511-3bc5-11ef-9b9f-28d0ea5d9ad4\n",
      "Subject registered at subject id: 71211d07-3bc5-11ef-8ea7-28d0ea5d9ad4\n",
      "Subject registered at subject id: 714d0173-3bc5-11ef-b2fc-28d0ea5d9ad4\n",
      "Subject registered at subject id: 717edf82-3bc5-11ef-8d66-28d0ea5d9ad4\n",
      "Subject registered at subject id: 71aba28d-3bc5-11ef-be91-28d0ea5d9ad4\n",
      "Subject registered at subject id: 71da655c-3bc5-11ef-afd7-28d0ea5d9ad4\n"
     ]
    }
   ],
   "source": [
    "for subject_path in glob.glob('data/db_raw/*'):\n",
    "    subject = subject_path.split(\"\\\\\")[-1]\n",
    "    registration.register(subject)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "facerecognition-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
